# –°–æ–∑–¥–∞–¥–∏–º –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–≥–æ –±–æ—Ç–∞ –æ–±—É—á–µ–Ω–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É
neural_network_code = '''
import numpy as np
import pandas as pd
import json
import re
import random
from collections import Counter
import pymorphy3
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import telebot
from googletrans import Translator

class RussianEnglishBot:
    def __init__(self, token):
        self.bot = telebot.TeleBot(token)
        self.morph = pymorphy3.MorphAnalyzer()
        self.translator = Translator()
        self.stop_words = set(stopwords.words('russian'))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        self.words = []
        self.classes = []
        self.documents = []
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        self.load_training_data()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—à–∫–∞ —Å–ª–æ–≤
        self.create_training_data()
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        self.build_neural_network()
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.train_model()
        
        # –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        self.user_data = {}
        
    def load_training_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        with open('russian_english_bot_training_data.json', 'r', encoding='utf-8') as f:
            self.intents = json.load(f)
        
        for intent in self.intents['intents']:
            for pattern in intent['patterns']:
                # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                tokens = self.preprocess_russian_text(pattern)
                self.documents.append((tokens, intent['tag']))
                
                if intent['tag'] not in self.classes:
                    self.classes.append(intent['tag'])
                    
                for token in tokens:
                    if token not in self.words:
                        self.words.append(token)
                        
        self.words = sorted(list(set(self.words)))
        self.classes = sorted(self.classes)
        
    def preprocess_russian_text(self, text):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text = text.lower()
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'[^\w\s]', '', text)
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        tokens = word_tokenize(text, language='russian')
        
        # –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤
        processed_tokens = []
        for token in tokens:
            if token not in self.stop_words and len(token) > 2:
                # –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é pymorphy3
                lemma = self.morph.parse(token)[0].normal_form
                processed_tokens.append(lemma)
                
        return processed_tokens
    
    def create_training_data(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        training = []
        output = []
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –º–∞—Å—Å–∏–≤–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
        output_empty = [0] * len(self.classes)
        
        for doc in self.documents:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—à–∫–∞ —Å–ª–æ–≤
            bag = []
            pattern_words = doc[0]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—à–∫–∞ —Å–ª–æ–≤
            for word in self.words:
                bag.append(1 if word in pattern_words else 0)
                
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –≤—ã–≤–æ–¥–∞
            output_row = list(output_empty)
            output_row[self.classes.index(doc[1])] = 1
            
            training.append([bag, output_row])
            
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        random.shuffle(training)
        training = np.array(training, dtype=object)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ X –∏ Y
        self.train_x = list(training[:, 0])
        self.train_y = list(training[:, 1])
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy –º–∞—Å—Å–∏–≤—ã
        self.train_x = np.array([np.array(x) for x in self.train_x])
        self.train_y = np.array([np.array(y) for y in self.train_y])
        
    def sigmoid(self, x):
        """–°–∏–≥–º–æ–∏–¥–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"""
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
    
    def sigmoid_derivative(self, x):
        """–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —Å–∏–≥–º–æ–∏–¥–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏"""
        return x * (1 - x)
    
    def build_neural_network(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏
        self.input_size = len(self.train_x[0])
        self.hidden_size = 128
        self.output_size = len(self.classes)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        np.random.seed(1)
        self.weights_input_hidden = np.random.uniform(-1, 1, (self.input_size, self.hidden_size))
        self.weights_hidden_output = np.random.uniform(-1, 1, (self.hidden_size, self.output_size))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–º–µ—â–µ–Ω–∏–π
        self.bias_hidden = np.zeros((1, self.hidden_size))
        self.bias_output = np.zeros((1, self.output_size))
        
    def train_model(self, epochs=1000, learning_rate=0.1):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        for epoch in range(epochs):
            # –ü—Ä—è–º–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
            hidden_input = np.dot(self.train_x, self.weights_input_hidden) + self.bias_hidden
            hidden_output = self.sigmoid(hidden_input)
            
            output_input = np.dot(hidden_output, self.weights_hidden_output) + self.bias_output
            predicted_output = self.sigmoid(output_input)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—à–∏–±–∫–∏
            error = self.train_y - predicted_output
            
            # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
            output_delta = error * self.sigmoid_derivative(predicted_output)
            hidden_error = output_delta.dot(self.weights_hidden_output.T)
            hidden_delta = hidden_error * self.sigmoid_derivative(hidden_output)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
            self.weights_hidden_output += hidden_output.T.dot(output_delta) * learning_rate
            self.weights_input_hidden += self.train_x.T.dot(hidden_delta) * learning_rate
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–º–µ—â–µ–Ω–∏–π
            self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate
            self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate
            
            if epoch % 100 == 0:
                loss = np.mean(np.square(error))
                print(f'–≠–ø–æ—Ö–∞ {epoch}, –û—à–∏–±–∫–∞: {loss:.6f}')
                
    def bag_of_words(self, sentence):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–µ—à–∫–∞ —Å–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        sentence_words = self.preprocess_russian_text(sentence)
        bag = [0] * len(self.words)
        for s in sentence_words:
            for i, word in enumerate(self.words):
                if word == s:
                    bag[i] = 1
        return np.array(bag)
    
    def predict_class(self, sentence):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        bow = self.bag_of_words(sentence).reshape(1, -1)
        
        # –ü—Ä—è–º–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
        hidden_input = np.dot(bow, self.weights_input_hidden) + self.bias_hidden
        hidden_output = self.sigmoid(hidden_input)
        
        output_input = np.dot(hidden_output, self.weights_hidden_output) + self.bias_output
        result = self.sigmoid(output_input)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
        max_index = np.argmax(result)
        category = self.classes[max_index]
        probability = result[0][max_index]
        
        return category, probability
    
    def get_response(self, intent_tag, user_id):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∏–Ω—Ç–µ–Ω—Ç–∞"""
        list_of_intents = self.intents['intents']
        for i in list_of_intents:
            if i['tag'] == intent_tag:
                result = random.choice(i['responses'])
                
                # –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤
                if user_id in self.user_data:
                    user_stats = self.user_data[user_id]
                    result = result.format(
                        words_learned=user_stats.get('words_learned', 0),
                        study_time=user_stats.get('study_time', 0),
                        level=user_stats.get('level', '–ù–∞—á–∏–Ω–∞—é—â–∏–π')
                    )
                
                return result
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –ø–æ–Ω—è–ª –≤–∞—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
    
    def translate_text(self, text, src='auto', dest='en'):
        """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞"""
        try:
            translation = self.translator.translate(text, src=src, dest=dest)
            return translation.text
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {str(e)}"
    
    def update_user_progress(self, user_id, action):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user_id not in self.user_data:
            self.user_data[user_id] = {
                'words_learned': 0,
                'study_time': 0,
                'level': '–ù–∞—á–∏–Ω–∞—é—â–∏–π',
                'lessons_completed': 0
            }
        
        user_stats = self.user_data[user_id]
        
        if action == 'word_learned':
            user_stats['words_learned'] += 1
        elif action == 'lesson_completed':
            user_stats['lessons_completed'] += 1
            user_stats['study_time'] += 10  # 10 –º–∏–Ω—É—Ç –∑–∞ —É—Ä–æ–∫
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è
        words_count = user_stats['words_learned']
        if words_count < 50:
            user_stats['level'] = '–ù–∞—á–∏–Ω–∞—é—â–∏–π'
        elif words_count < 200:
            user_stats['level'] = '–ë–∞–∑–æ–≤—ã–π'
        elif words_count < 500:
            user_stats['level'] = '–°—Ä–µ–¥–Ω–∏–π'
        else:
            user_stats['level'] = '–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π'
    
    def setup_handlers(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        @self.bot.message_handler(commands=['start'])
        def send_welcome(message):
            welcome_text = """
üéì –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç–∞ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞!

–Ø –ø–æ–º–æ–≥—É –≤–∞–º:
üìö –ò–∑—É—á–∞—Ç—å –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞
üìñ –ü–æ–Ω–∏–º–∞—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏–∫—É
üó£ –ü—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ
üìä –û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å

–ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏–ª–∏ –∑–∞–¥–∞–π—Ç–µ –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å!
            """
            self.bot.reply_to(message, welcome_text)
        
        @self.bot.message_handler(func=lambda message: True)
        def handle_message(message):
            user_message = message.text
            user_id = message.from_user.id
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Ç–∞
            intent, confidence = self.predict_class(user_message)
            
            if confidence > 0.7:
                response = self.get_response(intent, user_id)
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∏–Ω—Ç–µ–Ω—Ç–æ–≤
                if intent == 'translation_request':
                    if len(user_message.split()) > 2:
                        text_to_translate = user_message.replace('–ø–µ—Ä–µ–≤–µ–¥–∏', '').replace('translate', '').strip()
                        translation = self.translate_text(text_to_translate)
                        response += f"\n\n–ü–µ—Ä–µ–≤–æ–¥: {translation}"
                
                elif intent == 'vocabulary_request':
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è
                    vocab_examples = [
                        "üçé Apple - —è–±–ª–æ–∫–æ",
                        "üè† House - –¥–æ–º", 
                        "üì± Phone - —Ç–µ–ª–µ—Ñ–æ–Ω",
                        "‚≠ê Star - –∑–≤–µ–∑–¥–∞",
                        "üåä Water - –≤–æ–¥–∞"
                    ]
                    response += "\n\n–í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è:\n" + "\n".join(random.sample(vocab_examples, 3))
                    self.update_user_progress(user_id, 'word_learned')
                
                elif intent == 'lesson_request':
                    self.update_user_progress(user_id, 'lesson_completed')
                
            else:
                response = "–Ø –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /start –¥–ª—è –ø–æ–º–æ—â–∏."
            
            self.bot.reply_to(message, response)
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
        self.setup_handlers()
        print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        self.bot.polling()

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
if __name__ == "__main__":
    # TOKEN = "–í–ê–®_TELEGRAM_BOT_TOKEN"
    # bot = RussianEnglishBot(TOKEN)
    # bot.run()
    print("–ö–æ–¥ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
'''

# –°–æ—Ö—Ä–∞–Ω–∏–º –∫–æ–¥ –≤ —Ñ–∞–π–ª
with open('russian_english_neural_bot.py', 'w', encoding='utf-8') as f:
    f.write(neural_network_code)

print("–§–∞–π–ª —Å –∫–æ–¥–æ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å–æ–∑–¥–∞–Ω: russian_english_neural_bot.py")

# –°–æ–∑–¥–∞–¥–∏–º —Ç–∞–∫–∂–µ —Ñ–∞–π–ª requirements.txt
requirements = """numpy>=1.19.0
pandas>=1.2.0
telebot>=0.0.4
pyTelegramBotAPI>=4.0.0
pymorphy3>=1.0.0
nltk>=3.6.0
googletrans==4.0.0-rc1
scikit-learn>=0.24.0
"""

with open('requirements.txt', 'w', encoding='utf-8') as f:
    f.write(requirements)

print("–§–∞–π–ª –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å–æ–∑–¥–∞–Ω: requirements.txt")
print("\n–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã:")
print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ —Å pymorphy3")
print("‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç—å –Ω–∞ NumPy –∏ pandas")
print("‚úÖ Telegram Bot API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è") 
print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–≤–æ–¥–∞")
print("‚úÖ –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
print("‚úÖ –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ")